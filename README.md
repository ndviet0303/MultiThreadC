# ğŸ§® Gaussian Elimination - Parallel Computing

Bá»™ 4 file tá»‘i giáº£n triá»ƒn khai thuáº­t toÃ¡n **Gaussian Elimination** giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh tuyáº¿n tÃ­nh vá»›i cÃ¡c mÃ´ hÃ¬nh song song khÃ¡c nhau.

## ğŸ“‚ Cáº¥u trÃºc dá»± Ã¡n

```
MultiThreadC/
â”œâ”€â”€ sequential.c     # PhiÃªn báº£n tuáº§n tá»± (baseline)
â”œâ”€â”€ openmp.c        # Song song OpenMP (shared memory)
â”œâ”€â”€ pthread.c       # Song song Pthread (manual threading)
â”œâ”€â”€ mpi.c          # Song song MPI (distributed memory)
â”œâ”€â”€ Makefile       # Build script thÃ´ng minh
â”œâ”€â”€ README.md      # HÆ°á»›ng dáº«n nÃ y
â””â”€â”€ build/         # ThÆ° má»¥c chá»©a file executable
    â”œâ”€â”€ sequential
    â”œâ”€â”€ openmp
    â”œâ”€â”€ pthread
    â””â”€â”€ mpi
```

## âš¡ Báº¯t Ä‘áº§u nhanh

### 1. BiÃªn dá»‹ch táº¥t cáº£

```bash
make all
```

### 2. Cháº¡y test cÆ¡ báº£n

```bash
# Tuáº§n tá»± (baseline)
build/sequential 100

# OpenMP - 4 luá»“ng
build/openmp 100 4

# Pthread - 4 luá»“ng  
build/pthread 100 4

# MPI - 4 processes
mpirun -np 4 build/mpi 100
```

### 3. Test hiá»‡u nÄƒng

```bash
make test-performance
```

## ğŸ§ª Thuáº­t toÃ¡n

**Gaussian Elimination** vá»›i **Partial Pivoting**:

1. **Forward Elimination (Khá»­ xuÃ´i)**
   - TÃ¬m pivot lá»›n nháº¥t trong cá»™t hiá»‡n táº¡i
   - HoÃ¡n Ä‘á»•i hÃ ng Ä‘á»ƒ Ä‘Æ°a pivot lÃªn vá»‹ trÃ­ Ä‘Æ°á»ng chÃ©o
   - Khá»­ táº¥t cáº£ pháº§n tá»­ dÆ°á»›i pivot vá» 0

2. **Backward Substitution (Tháº¿ ngÆ°á»£c)**
   - Giáº£i tá»« phÆ°Æ¡ng trÃ¬nh cuá»‘i cÃ¹ng lÃªn Ä‘áº§u
   - Tháº¿ ngÆ°á»£c Ä‘á»ƒ tÃ¬m nghiá»‡m hoÃ n chá»‰nh

**Äá»™ phá»©c táº¡p**: O(nÂ³) cho táº¥t cáº£ phiÃªn báº£n

## ğŸš€ Chiáº¿n lÆ°á»£c song song

### ğŸ”¸ Sequential (`sequential.c`)
- **MÃ´ hÃ¬nh**: Tuáº§n tá»± hoÃ n toÃ n
- **Má»¥c Ä‘Ã­ch**: Baseline Ä‘á»ƒ so sÃ¡nh hiá»‡u nÄƒng
- **Æ¯u Ä‘iá»ƒm**: ÄÆ¡n giáº£n, dá»… hiá»ƒu, Ã­t lá»—i
- **NhÆ°á»£c Ä‘iá»ƒm**: Cháº­m vá»›i ma tráº­n lá»›n

### ğŸ”¸ OpenMP (`openmp.c`)
- **MÃ´ hÃ¬nh**: Shared memory parallelism
- **Ká»¹ thuáº­t**: `#pragma omp parallel for` 
- **Song song hÃ³a**: VÃ²ng láº·p khá»­ xuÃ´i
- **Æ¯u Ä‘iá»ƒm**: Dá»… code, hiá»‡u quáº£ cao
- **NhÆ°á»£c Ä‘iá»ƒm**: Giá»›i háº¡n trong 1 mÃ¡y

### ğŸ”¸ Pthread (`pthread.c`)
- **MÃ´ hÃ¬nh**: Manual thread management
- **Ká»¹ thuáº­t**: Thread pool + mutex synchronization
- **Song song hÃ³a**: TÃ¬m pivot vÃ  khá»­ hÃ ng
- **Æ¯u Ä‘iá»ƒm**: Kiá»ƒm soÃ¡t chi tiáº¿t
- **NhÆ°á»£c Ä‘iá»ƒm**: Phá»©c táº¡p, dá»… deadlock

### ğŸ”¸ MPI (`mpi.c`)
- **MÃ´ hÃ¬nh**: Distributed memory parallelism
- **Ká»¹ thuáº­t**: Row distribution + collective communication
- **Song song hÃ³a**: PhÃ¢n phá»‘i hÃ ng cho processes
- **Æ¯u Ä‘iá»ƒm**: Má»Ÿ rá»™ng nhiá»u mÃ¡y
- **NhÆ°á»£c Ä‘iá»ƒm**: Overhead communication

## ğŸ“Š So sÃ¡nh hiá»‡u nÄƒng

| MÃ´ hÃ¬nh | Kiáº¿n trÃºc | Speedup lÃ½ thuyáº¿t | PhÃ¹ há»£p |
|---------|-----------|-------------------|---------|
| Sequential | Single-threaded | 1.0x | Ma tráº­n nhá» |
| OpenMP | Multi-threaded | 2-8x | Workstation |
| Pthread | Multi-threaded | 2-6x | Embedded systems |
| MPI | Multi-process | 2-Nx | HPC clusters |

## ğŸ› ï¸ YÃªu cáº§u há»‡ thá»‘ng

### Báº¯t buá»™c:
- **GCC** vá»›i OpenMP support
- **POSIX Threads** (pthread)
- **Make** build tool

### TÃ¹y chá»n (cho MPI):
- **OpenMPI** hoáº·c **MPICH**

### CÃ i Ä‘áº·t:

**macOS:**
```bash
# CÃ i Ä‘áº·t dependencies cho OpenMP vÃ  MPI
brew install gcc libomp open-mpi

# Kiá»ƒm tra gcc cÃ³ sáºµn
which gcc-13 || which gcc-12
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install build-essential libgomp1 libopenmpi-dev openmpi-bin
```

**LÆ°u Ã½ quan trá»ng:**
- **Sequential vÃ  Pthread**: Hoáº¡t Ä‘á»™ng trÃªn má»i há»‡ thá»‘ng cÃ³ GCC
- **OpenMP**: Cáº§n homebrew GCC trÃªn macOS, system GCC trÃªn Linux
- **MPI**: Cáº§n cÃ i Ä‘áº·t OpenMPI hoáº·c MPICH

## ğŸ“ˆ Test hiá»‡u nÄƒng chi tiáº¿t

### Test vá»›i cÃ¡c sá»‘ luá»“ng khÃ¡c nhau:

```bash
# OpenMP scalability
for threads in 1 2 4 6 8; do
    echo "=== OpenMP $threads threads ==="
    time build/openmp 1000 $threads
done

# Pthread scalability  
for threads in 1 2 4 6 8; do
    echo "=== Pthread $threads threads ==="
    time build/pthread 1000 $threads
done

# MPI scalability
for procs in 1 2 4 6 8; do
    echo "=== MPI $procs processes ==="
    time mpirun -np $procs build/mpi 1000
done
```

### Äo speedup tá»± Ä‘á»™ng:

```bash
#!/bin/bash
n=1000

# Baseline
echo "Measuring baseline..."
seq_time=$(build/sequential $n | grep "Thá»i gian" | awk '{print $4}')

# OpenMP speedup
omp_time=$(build/openmp $n 4 | grep "Thá»i gian" | awk '{print $4}')
omp_speedup=$(echo "scale=2; $seq_time / $omp_time" | bc)

echo "Sequential: ${seq_time}s"
echo "OpenMP:     ${omp_time}s (${omp_speedup}x speedup)"
```

## ğŸ¯ Káº¿t quáº£ máº«u

```
=== PERFORMANCE TEST (n=500) ===

Sequential:
  Time: 0.234567 seconds
  
OpenMP (4 threads):  
  Time: 0.089123 seconds
  Speedup: 2.63x
  Efficiency: 65.8%
  
Pthread (4 threads):
  Time: 0.094521 seconds  
  Speedup: 2.48x
  Efficiency: 62.0%
  
MPI (4 processes):
  Time: 0.156789 seconds
  Speedup: 1.50x
  Efficiency: 37.5%
```

## ğŸ”¬ PhÃ¢n tÃ­ch thuáº­t toÃ¡n

### Pháº§n song song hÃ³a Ä‘Æ°á»£c:
- **Forward elimination**: Khá»­ cÃ¡c hÃ ng Ä‘á»™c láº­p âœ…
- **Pivot selection**: TÃ¬m max cÃ³ thá»ƒ song song âœ…

### Pháº§n tuáº§n tá»± (bottleneck):
- **Backward substitution**: Phá»¥ thuá»™c tuáº§n tá»± âŒ
- **Row swapping**: Cáº§n Ä‘á»“ng bá»™ âŒ

### Giá»›i háº¡n Speedup (theo Amdahl's Law):
```
S = 1 / (f + (1-f)/p)
```
Vá»›i `f â‰ˆ 30%` pháº§n tuáº§n tá»± â†’ Speedup max â‰ˆ 3.3x

## ğŸ§® Ma tráº­n test

**Dominant Diagonal Matrix**: Äáº£m báº£o kháº£ nghá»‹ch vÃ  numerical stability

```c
// Cáº¥u trÃºc ma tráº­n
A[i][i] = n + 10.0          // ÄÆ°á»ng chÃ©o lá»›n
A[i][j] = 1.0/(i+j+1.0)     // Pháº§n tá»­ khÃ¡c nhá»

// Nghiá»‡m test
x[i] = i + 1.0              // [1, 2, 3, ..., n]

// Vector b
b = A * x                   // TÃ­nh tá»« nghiá»‡m Ä‘Ã£ biáº¿t
```

## ğŸ› Troubleshooting

### Lá»—i compilation OpenMP:
```bash
# Thá»­ compiler khÃ¡c
clang -fopenmp -Xpreprocessor -fopenmp -lomp -o openmp openmp.c
```

### Lá»—i MPI khÃ´ng tÃ¬m tháº¥y:
```bash
# Kiá»ƒm tra MPI installation
which mpicc
which mpirun

# Set PATH náº¿u cáº§n
export PATH="/usr/local/bin:$PATH"
```

### Lá»—i linking pthread:
```bash
# Explicit linking
gcc -pthread -lpthread -o pthread pthread.c
```

### Ma tráº­n singular:
```bash
# Giáº£m kÃ­ch thÆ°á»›c test
build/sequential 10

# Ma tráº­n dominant diagonal ráº¥t Ã­t khi singular
```

## ğŸ“‹ Makefile targets

```bash
make help                # Hiá»ƒn thá»‹ trá»£ giÃºp
make all                 # Build táº¥t cáº£ 
make sequential          # Build tuáº§n tá»±
make openmp              # Build OpenMP
make pthread             # Build Pthread  
make mpi                 # Build MPI
make test-small          # Test ma tráº­n 10x10
make test-performance    # Test ma tráº­n 500x500
make clean               # XÃ³a thÆ° má»¥c build/
```

## ğŸ“š TÃ i liá»‡u tham kháº£o

1. **Thuáº­t toÃ¡n**: Introduction to Algorithms (CLRS) - Chapter 28
2. **OpenMP**: OpenMP Application Programming Interface
3. **Pthread**: Programming with POSIX Threads (David Butenhof)
4. **MPI**: Using MPI - Portable Parallel Programming (Gropp, Lusk, Skjellum)
5. **Parallel Algorithms**: Introduction to Parallel Algorithms (JÃ¡JÃ¡)

## ğŸ“ á»¨ng dá»¥ng thá»±c táº¿

- **Scientific Computing**: MÃ´ phá»ng váº­t lÃ½, hÃ³a há»c
- **Machine Learning**: Linear regression, neural networks
- **Computer Graphics**: Lighting, rendering pipelines
- **Engineering**: FEM, CFD simulations
- **Economics**: Linear programming, optimization

---

**TÃ¡c giáº£**: Implementation for Parallel Computing Education  
**PhiÃªn báº£n**: Tá»‘i giáº£n 4-file standalone  
**NgÃ´n ngá»¯**: C with OpenMP/Pthreads/MPI  
**License**: Educational use 